\فصل{روش پیشنهادی}

در این قسمت به روش‌های توسعه داده‌شده و نحوه به دست آمدن نتایج و خروجی‌ها می‌پردازیم. فرآیند به این صورت طی می‌شود که ابتدا دستورالعمل مناسب براساس شرط‌های مشخص شده انتخاب می‌شود و سپس در صورت نیاز نمونه‌های مشابه به خبر مورد نظر در دستور آمده و سپس مدل‌های زبانی‌ بزرگ ۸ یا ۹ میلیارد پارامتر روی کارت گرافیکی بالا آمده و به صورت دسته‌های ۱۰‌تایی نتایج از خروجی این مدل‌ها ذخیره شده و تحلیل‌ها روی آن انجام می‌شود.

\قسمت{انواع دستورالعمل‌های توسعه‌داده شده}
در اینجا به چهار حالت پرامپت‌ها یا همان دستعورالعمل‌ها را که به‌کار گرفته شده است پرداخته می‌شود و کاربرد و اهداف هرکدام بررسی می‌شود. یک دستورالعمل
$p_i$
از یک مجموعه
$P = \{p_1, p_2, \ldots, p_n\}$
انتخاب می‌شود و براساس آن نتایج خروجی که به صورت برچسب‌های
$l_j = <0,1>$
مشخص می‌شود خروچی گرفته می‌شود.

\زیرقسمت{دستورالعمل‌های وانیلا}
دستورالعمل‌های وانیلا\پانویس{Vanila} که همان دستورالعمل‌های خام بوده صرفا اطلاعات مورد نیاز را برای مدل‌های زبانی بزرگ تهیه و توضیح می‌دهد. در ابتدا وظیفه طبقه‌بندی انجام شده توضیح داده‌می‌شود و سپس مشخص می‌شود که حتما خروجی به حالت 
$l_j = <0,1>$
می‌بایست باشد و چندین بار روی این موضوع تاکید می‌شود تا مطمئن شویم خروجی این مدل‌ها صرفا یک برچسب باشد. سپس توضیح اخبار مهم براساس دسته‌های مختلف تهیه شده و درنهایت خبری که می‌خواهیم طبقه‌بندی شود در پایان این دستور می‌آید. برای نمونه می‌توان یک دستور را به شکل زیر مشاهده کنیم:

\vspace{5pt}
\begin{scriptsize}
\begin{itshape}
    برای این وظیفه‌ی طبقه‌بندی، از شاخه‌های فکری زیر استفاده کنید تا تصمیم بگیرید که آیا خبر «مهم» (۱) است یا «غیر مهم» (۰):

    ۱. ابتدا بررسی کنید که آیا موضوع خبر می‌تواند بخش بزرگی از کاربران فارسی‌زبان را تحت تأثیر قرار دهد و به گستردگی احتمالی آن توجه کنید.
    ۲. سپس محتوای موضوع را از نظر اهمیت اقتصادی، سیاسی و اجتماعی تحلیل کنید.
    
    برای اخبار اقتصادی: عواملی مانند تورم، وضعیت مسکن و روندهای بورس که برای کاربران عادی اهمیت دارند را مدنظر قرار دهید.
    
    برای اخبار سیاسی: ارزیابی کنید که آیا محتوا به سیاست‌های کلان ایران، تغییرات مهم در دولت، یا تعاملات جهانی مربوط می‌شود.
    
    برای اهمیت اجتماعی: بررسی کنید که آیا خبر شامل رویدادهای ورزشی محبوب یا موضوعاتی با جذابیت گسترده است.
    
    ۳. بررسی کنید که آیا جذابیت خبر عمومی است یا فقط برای مخاطبان خاصی جذابیت دارد.
    
    اگر خبر از نظر گسترده‌ای مهم است، آن را با «۱» برچسب بزنید. در غیر این صورت، اگر بیشتر برای مخاطبان خاص جذاب است، «۰» را انتخاب کنید. تحلیل این سناریوها را به پایان رسانده و طبقه‌بندی نهایی را به‌صورت زیر ارائه دهید:
    
    طبقه بندی نهایی: «۰ یا ۱»
\end{itshape}
\end{scriptsize}
\vspace{5pt}

که این نمونه آورده شده شامل مفهوم درخت‌های تفکر نیز می‌شود. نمونه‌های بیشتر این نوع دستورالعمل‌ها را می‌توانید در قسمت مطالب تکمیلی مشاهده کنید.

\زیرقسمت{دستورالعمل‌های چندنمونه‌ای}
در این نوع دستورالعمل‌ها علاوه برای بر محتوای خود پرامپت، چندین نمونه براساس خبر خواسته شده نیز آورده می‌شود. فرض کنید خبری که اکنون می‌خواهیم طبقه بندی کنیم به صورت
$t_i$
از مجموعه دادگان تست یعنی
$T = \{t_1, t_2, \ldots, t_n\}$
باشد. آنگاه به ازای هر هر تایتل یا عنوان خبر در دادگان آموزش خود متن و همچنین نسخه برداری آن را به وسیله مدل TF-IDF خواهیم داشت که به این صورت تعریف می‌شود:
\begin{equation}
    S_{<Title>} = \{s_1, s_2, \ldots, s_n\} \xrightarrow{TF-IDF} V_{<Title, TF-IDF>} = \{v_1, v_2, \ldots, v_n\}
\end{equation}

که در آن
$s_i$
مشخص کننده یک نمونه و 
$v_j$
نشان‌دهنده بردار شده است. پس از این اقدام با روش
$cosine\,similarity$
از تمامی بردار‌ها، براساس
$k$
انتخابی یا همان تعداد نمونه‌ها، شبیه‌ترین عناوین خبرها را همراه برچسب اهمیت‌ آنها قرار می‌دهیم.
\begin{equation}
    E_{<samples>} = \{<s_i, l_i> | s_i \in \text{argmax}_{k}\left(cosine(V_{<Title, TF-IDF>}, t_i)\right)\}
\end{equation}

این نمونه‌های کمک می‌کند که مدل‌ مشاهده کند که هرکدام از اخبار شبیه به خبر داده شده به چه صورت از نظر اهمیت ارزیابی شده است و سپس تصمیم‌ نهایی خود را براساس آن تغییر دهد. نمونه‌های در دستور العمل به این صورت قرار می‌گیرد:

\vspace{5pt}
\begin{scriptsize}
\begin{itshape}
نمونه‌ها: به نمونه‌های زیر نگاه کنید و بر اساس آنها تشخیص دهید که کدام خبرها مهم هستند و با عدد '۰' نمایش داده می‌شوند و کدام خبرها غیرمهم هستند و با عدد '۱' نمایش داده می‌شوند.
\vspace{3pt}

نمونه: هشدار؛ بارش باران و برف در این استان‌ها طبقه بندی نهایی: 1

نمونه: بارش برف و باران در جاده‌های ۱۴ استان طبقه بندی نهایی: 1

نمونه: پیش‌بینی بارش برف و باران در این استان‌ها/ گرم‌ترین و سردترین شهرها کدامند؟ طبقه بندی نهایی: 1

نمونه: بارش برف و باران از فردا در این استان‌ها شروع می‌شود طبقه بندی نهایی: 1

نمونه: پیش‌بینی بارش ۵ روزه در ۸ استان طبقه بندی نهایی: 1

نمونه: پیش‌بینی رگبار و رعدوبرق طی ۵ روز آتی در برخی نقاط کشور/وزش باد شدید در شرق طبقه بندی نهایی: 1

نمونه: بارش باران در نقاط مختلف کشور طبقه بندی نهایی: 1

نمونه: هشدار! دیگر بارش برف و باران هم تاثیر چندانی در آلودگی هوا ندارد طبقه بندی نهایی: 0

نمونه: ثبت بیش از ۲۳ میلیون سفر نوروزی فقط در روز گذشته | بارش برف و باران در جاده‌های ۴ استان طبقه بندی نهایی: 0

نمونه: بارش برف و باران در جاده‌های ۵ استان | رانندگان قبل از سفر حتما با این سامانه تماس بگیرند طبقه بندی نهایی: 0

نمونه: هوای تهران در آخر هفته | چه خبر از بارش برف و باران؟ طبقه بندی نهایی: 0

نمونه: ورود سامانه بارشی ؛ بارش باران در ۸ استان طی ۲۴ ساعت آینده | تهران و ۳ استان دیگر منتظر وزش باد شدید باشند طبقه بندی نهایی: 1

نمونه: بارش باران و تگرگ در آذربایجان غربی طبقه بندی نهایی: 0

نمونه: تشدید بارش‌ها از فردا در کشور ؛ بارش برف در تهران | کاهش ۴ تا ۸ درجه‌ای دما در نوار شمالی طبقه بندی نهایی: 1

نمونه: بارش برف و باران در این ۱۱ استان | آماده‌باش امدادگران هلال احمر | ورود سامانه بارشی جدید به کشور از امروز طبقه بندی نهایی: 1

نمونه: تداوم بارش در برخی استان‌ها / وزش باد شدید و خیزش گرد و خاک در شرق کشور طبقه بندی نهایی: 1

نمونه: هشدار هواشناسی | افزایش آلودگی هوا در ۲ کلانشهر | وزش باد شدید و ارتفاع امواج در ۳ استان طبقه بندی نهایی: 0

نمونه: پیش بینی بارش ها در کشور | امروز پنجشنبه فقط ۲ استان بارندگی ندارد |  گرمترین و سردترین شهرهای کشور طبقه بندی نهایی: 1

نمونه: عکس ا اقدام عجیب عراق در جعل نام خلیج فارس طبقه بندی نهایی: 1

نمونه: باخت برانکو به عراق در فینال جام خلیج‌فارس طبقه بندی نهایی: 0

\end{itshape}
\end{scriptsize}
\vspace{5pt}


\زیرقسمت{دستورالعمل‌های زنجیره تفکر}
در این نوع دستورها، از مدل زبانی بزرگ خواسته می‌شود که صرفا به یک زاویه دید اتکا نکند و موقعیت‌های مختلف را بررسی کند. بعضا در این حالت به مدل اجازه می‌دهیم که خروجی خود را فراتر از برچسب
$l_j = <0,1>$
ببرد و سعی کند تفکرات خود را بسازد و سپس طبقه‌بندی نهایی را در یک قالب مشخص بیان کند که سپس بتوان آن را استخراج کرد. برای نمونه یک نوع از این پرامپت‌های استفاده در زبان انگلیسی را می‌توانید به صورت زیر مشاهده کنید:
\pagebreak

\vspace{5pt}
\begin{scriptsize}
\begin{itshape}
\begin{latin}
\LTR
The goal is to classify news items into 'important' (1) or 'not important' (0). To classify accurately, follow these steps:

1. Identify if the news topic could be relevant to a large Persian-speaking audience.

2. Assess if it pertains to significant economic events (currency or inflation changes, housing updates, etc.), critical political events (government actions, international relations), or socially impactful themes that could affect many people.

3. Finally, determine if the story has widespread appeal or is only relevant to a niche audience.

If the news is of broad interest and covers the themes above, label it as '1'. Otherwise, label it as '0'. Upon completing the scenario analysis, output the final classification using the format below:

Final Classification: [1 or 0]
\RTL
\end{latin}
\end{itshape}
\end{scriptsize}
\vspace{5pt}

\زیرقسمت{دستعورالعمل‌ها درخت تفکر}
در این حالت از دستورها، علاوه بر زنجیره تفکر از مدل خواسته می‌شود که در یک یا دو تا از زنجیره‌ها، حالت‌های دیگر را به صورت درختی بررسی کند. در اینجا، از آنجایی که هدف ما طبقه‌بندی اخبار است خواسته شده که در انواع دسته‌بندی خبرها همانند اقتصادی، فرهنگی، سلامت و بهداشت و ورزشی مدل در خصوص اهمیت خبر فکر کرده و سپس اظهار نظر کند.

\قسمت{رویکرد دستورالعمل سیستمی و کاربر}
یکی از رویکردهایی که در این پژوهش مورد بررسی قرار گرفته بررسی تاثیر تعریف قاعده‌مند دستور سیستمی و کاربری و جداسازی آن و تاثیر آن برای دقت خروجی مدل‌های زبانی بزرگ است. دستورالعمل سیستمی، دستوری است که معمولا ثابت است و وظایف اصلی را برای مدل شرح می‌دهد که طبق آن به دستور کاربر پاسخ دهد.

در این پژوهش قواعد اصلی، تعریف مهم و غیرمهم بودن خبر، نمونه‌ها و شرح اصلی به صورت دستعورالعمل‌ سیستمی تعریف شده و خود خبری که می‌خواهیم مورد طبقه‌بندی قرار دهیم به صورت دستعورالعمل‌ کاربر\پانویس{User Prompt} تعریف شده است. این رویکرد با رویکرد دستعورالعمل یکپارچه مقایسه شده و در قسمت نتایج مشاهده شده که تعریف جداگانه آنها به بهبود کارایی مدل‌ها کمک شایانی می‌کند.

\قسمت{تحلیل قدرت استدلال در حالت چند زبانی}
در این پژوهش این سوال مورد هدف قرار گرفته است که تقاوتی بین دستورالعمل به زبان انگلیسی و فارسی وجود دارد؟ آیا مدل‌های زبان بزرگ فرهنگ و موقعیت‌ جفرافیای کشور ایران را بیشتر در زبان فارسی ذخیره و استدلال می‌توانند بکنند و یا اینکه در حالتی که به صورت زبان انگلیسی به آنها دستور دهیم قدرت استدلال بیشتری خواهند داشت؟ با بررسی دستور‌های سیستمی در فصل نتایج به هر دو زبان، نتایج به دست آمده حاکی است که در یکسری شرایط خاص و وابسته به مدل استفاده شده، تفاوت عملکرد متفاوت است به طوری که در دستورهای وانیلا در زبان انگلیسی قدرت استدلال بیشتر و در حالت‌های درخت تفکر و زنجیره تفکر به نظر می‌آید در زبان فارسی قدرت تفکر بیشتری داریم.

\قسمت{رویکرد تنظیم نمادها}
این رویکرد که الهام گرفته از روش معرفی شده در مقاله\مرجع{wei2023symboltuningimprovesincontext}
هست بر این عنوان تمرکز می‌کند که به جای قرار دادن تعریف برچسب‌های اصلی برای یک مدل زبانی بزرگ یا همان
$l_j = <0,1>$
به جای برچسب‌های اصلی، برچسب‌های نمادین و بی‌ارتباط استفاده شود و قدرت مدل در این سناریو بررسی شود.

در نگاه اول شاید سوال پیش بیایید که چرا اصلا این رویکرد موثر واقع خواهد شد؟ و چرا قرار ندادن واژه‌های «مهم» و «غیرمهم» و گمراه کردن مدل با سمبل‌های غیر مرتبط در نهایت می‌تواند به دقت مدل کمک کند؟ جواب این سوال‌ها را باید اینطور داد که تنظیم نمادها این هدف را دنبال می‌کند که مدل زبانی بزرگ نتواند به دانش پیشینه خود که روی آن آموزش دیده تکیه کند و تمامی خروجی‌ها را براساس نمونه‌های قرار داده شده در دستور یادبگیرد و پیش‌بینی کند.

در سناریو تشخیص اهمیت اخبار، بسیاری از اوقات مشاهده می‌شود که این مدل‌های رویکردی غیر از فرهنگ مربوط به کشور ایران در پیش‌بینی اهمیت اخبار به کار می‌برد زیرا که بیشتر داده‌های‌ آموزش خود به زبان انگلیسی بوده و شاید یک چیز بی‌اهمیت برای یک فرد ایرانی، در فرهنگ غرب بسیار مهم واقع شود.

در این شرایط نیاز داریم که مدل بسیار بیشتر به مثال‌ها و نمونه‌های قرار داده شده توجه کند. در این پژوهش به جای برچسب‌های «مهم» و «غیرمهم» از برچسب‌های «۵۸» و «۴۷» استفاده شده است تا مدل را از دانش پیشینه خود محروم کند. یعنی در پرامپت قرار گرفته برای مدل هیچ واژه «مهم» یا «غیرمهم» وجود نداشته و مدل براساس مثال‌ها و تعاریف‌ها باید مفهوم دو برچسب «۵۸» و «۴۷» را یادبگیرد و سپس برچسب‌ نهایی را براساس این دو پیش‌بینی کند.
\begin{equation}
    l_j = <0,1> \quad \xrightarrow{Symbol Tuning} \quad l_{<Symbolic>} = <47, 58>
\end{equation}

یکی از کاربردهای دیگر این روش نیز سنجیدن حساسیت‌ مدل‌ها به دستور داده شده است، از آنجایی که مدل نمی‌تواند به دانش پیشینه خود تکیه کند بسیار بیشتر به محتوای دستور حساس‌تر شده و با سنجیدن آنها به وسیله
$K$
های مختلف نمونه‌ها می‌توان رویکرد‌های جالبی از عملکرد این مدل‌ها و حساسیتی که به پراپمت نشان می‌دهد بررسی کرد.

\قسمت{تنظیم براساس دستورالعمل و حالت‌های مختلف آن}
در رویکردی که در پرامپت یک شرح دستور و نمونه می‌آوریم چهار حالت ممکن طبق \رجوع{شکل:دستورالعمل و برچسب‌} داریم.

\شروع{شکل}[ht]
\centerimg{image1}{15cm}
\شرح{حالت‌های مختلف یک دستورالعمل و برچسب‌های آن}
\برچسب{شکل:دستورالعمل و برچسب‌}
\پایان{شکل}

که همانطور که مشخص است چهار حالت داریم که در یکسری از حالت شرح خود وظیفه کامل مشخص است و در دیگر حالت‌ها صرفا به آوردن نمونه اتکا شده است. و همچنین حالت‌های دیگر به وسیله آوردن برجسب‌های مرتبط و غیرمرتبط شکل می‌گیرد.

در این کار، دو حالت شرح وظیفه به همراه برچسب مرتبط و شرح وظیفه به همراه برچسب غیرمرتبط بررسی شده است. آز آنجایی که بدون شرح وظیفه درک اینکه برچسب‌ها چه مفهمومی برای مدل زبانی بزرگ در تشخیص اهمیت خبر دارد بسیار پیچیده و مبهم می‌شود، به بررسی اینگونه حالات در این پژوهش نپرداخته شده است.

\قسمت{انواع متن بررسی شده از اخبار}
همانطور که می‌دانیم یک متن خبری منتشر شده در سایت‌های دارای یک عنوان و یک متن است که هرکدام از آنها را می‌توان به صورت جداگانه بررسی کرد. علاوه براینها دادگان جمع‌شده از سایت‌های خبری شامل یک خلاصه بوده که از مدل‌های زبانی بزرگ گرفته شده است. بنابراین نمونه خبری
$t_i$
که می‌خواهیم نوع آن را بررسی کنیم می‌تواند در سه حالت زیر قرار بگیرد.
\begin{equation}
    Type(t_i) \in \{T_{<Title>}, T_{<Summery>}, T_{<Text>}\}
\end{equation}

در خصوص نمونه‌های
$e_i$
که برای یادگیری مدل مورد استفاده قرار می‌گیرد صرفا از عنوان خبرها یا همان
$T_<Title>$
استفاده شده است زیرا که برای مد‌ل‌های زبانی بزرگ دچار محدودیت برای ورودی هستیم و در حالت‌های
$K = 20$
 و
$k = 50$
دچار این محدودیت شده اگر بخواهیم از نوع‌های
$T_{<Summery>}$
و یا
$T_{<Text>}$
استفاده کنیم، بنابراین مجموعه
$E$
همواره از توزیع عنوان خبرها خواهد بود.

\قسمت{نحوه خروجی گرفتن از مدل‌های زبانی بزرگ}
یکی از چالش‌های اصلی خروجی گرفتن از این مدل‌ها مقدار رم گرافیکی مورد استفاده قرار گرفته است. به طوری که عملا خروجی گرفتن از مدل‌های بزرگتر از ۱۲ میلیاردی را غیرممکن می‌سازد.

در این پژوهش با استفاده از روش و تکنینک
\lr{4bit Quantized}
و لود کردن پارامترها در مقدار
\lr{Float4}
به جای
\lr{Float32}
می‌توانیم در مقدار رم گرفیکی ۱۶ گیگ مدل را بارگذاری کرده و از آن خروجی گرفت.

\زیرقسمت{مدل‌های زبانی بزرگ استفاده شده}
در این کار، از دو مدل‌های زبانی بزرگ موجود به صورت عمومی یعنی مدل آیا ۲۳\پانویس{Aya23} با ۸ میلیارد پارامتر و مدل جما ۲ با ۹ میلیارد\پانویس{Gemma2-9b-instruct} پارامتر استفاده شده است.

همچنین کارت گرافیکی استفاده شده در اینجا، کارت گرافیکی
\lr{P100}
با مقدار رم گرافیکی ۱۶ گیگ بوده و تمامی خروجی‌ها براساس این گرفته شده است.

\زیرقسمت{نحوه بهینه خروجی گرفتن از مدل‌های زبانی بزرگ}
در این پژوهش از معماری
\lr{Fast Attension}\مرجع{dao2022flashattentionfastmemoryefficientexact}
به جای معماری توجه ساده استفاده شده زیرا که این معماری دارای سرعت بسیار بالاتر به وسیله‌ بهبود ضرب‌های ماتریسی از پیش تعریف شده است.

همچنین خروجی و ورودی‌های
\lr{I/O}
به کمترین حالت خود رسیده تا بتوان در سریع‌ترین حالت ممکن از کل دادگان تست خروچی گرفت.

\قسمت{چرخه کلی خروجی گرفتن‌ها}
در نهایت شبه‌کد زیر، روند کلی ساخت دستورالعمل‌ها با توجه به نمونه‌های و ورودی خبر به عنوان دستور کاربر نشان می‌دهد. در این چرخه از دو حلقه بسته به $K$ انتخابی بهره گرفته می‌شود و برای به حداقل رساندن
$I/O$
نتایج به صورت دسته‌های ۲۰‌تایی ذخیره می‌شود.

\pagebreak

\شروع{الگوریتم}{ساخت دستور و خروجی گرفتن برچسب پیش‌بینی شده توسط مدل زبانی بزرگ}
\ورودی خبر $t_i$ از دادگان تست به عنوان دستور کاربر
\خروجی برچسب
$l_j = \{<0,1> \, or \, <47,58>\}$
به عنوان پیش‌بینی مدل از اهمیت خبر

\دستور انتخاب مدل $M$ و پرامپت $p_i$ از مجموعه $P = \{p_1, \ldots, p_n\}$
\دستور قراردادن مقدار $K$ به عنوان تعداد نمونه
\دستور انتخاب $Type(t_i)$ از مجموعه $\{T_{<Title>}, T_{<Summery>}, T_{<Text>}\}$
\تاوقتی{مجموعه $T$ اتمام نشود}
    \اگر{$K \ne 0$}
        \دستور ساخت فضای برداری $V$ از تمامی فضای نمونه
        \دستور $\leftarrow$ $V_{{<Title, TF-IDF>}} = \{v_i\,|\, v_i = R_{TF-IDF}(e_i \in E)\}$
        \دستور ساخت فضای برداری $v^{(t_i)}$ از ورودی $t_i$
        \تاوقتی{$K$ نمونه انتخاب نشده است}
            \دستور انتخاب $e_i$ از مجموعه $E$
        \دستور $\leftarrow$ $e_i = \{<s_i, l_i> | s_i \in \text{argmax}\left(cosine(V_{<Title, TF-IDF>}, v^{(t_i)})\right)\}$
        \پایان‌تاوقتی
        \دستور ساخت افزودن مجموعه نمونه $E^{(K)}$ به پرامپت $p_i$
    \پایان‌اگر
    \دستور گرفتن خروجی برچسب از مدل
    $\leftarrow$ $l_i = M(p_i, t_i)$
    \دستور ذخیره نتایج برچسب‌ها $l_i$ به همراه پرامپت‌های $p_i$ به صورت دسته‌های ۲۰تایی
\پایان‌تاوقتی
\دستور ذخیره دادگان و نتایج کلی
\پایان{الگوریتم}

که درنهایت خروجی برای تحلیل داده‌ای و به دست آمدن دقت‌ها فراهم می‌شود.


\قسمت{ساختار نتایج}
نتایج به دست آمده در یک فایل
\lr{CSV}
ذخیره شده که تمامی حالات مختلف $K$  را در خود داشته و هچنین عنوان خبر، برچسب اصلی $t_i$، برچسب‌های پیش‌بینی شده $l_i^{(K)}$ و دسته‌بندی خبر یا همان $c_i$ در خود خواهد داشت.

برای نمونه ساختار نتایج به دست آمده را می‌توان در شکل \رجوع{شکل:ساختار نتایج} مشاهده کرد.


\شروع{شکل}[ht]
\centerimg{image2}{15cm}
\شرح{ساختار نتایج ذخیره شده و مشخص‌کردن برچسب‌های $l-i$ پیش‌بینی شده از مدل}
\برچسب{شکل:ساختار نتایج}
\پایان{شکل}

\قسمت{نحوه تحلیل نتایج}
از آنجایی که در دادگان تست، ناترازی داده‌ای داریم به صورتی که حدود یک پنچم داده‌ها مهم و مابقی غیرمهم بوده است (که نشان‌دهنده توزیعی از خبرها برای یک کاربر دارد) معیاری که برای دقت‌سنجی ما بسیار اهمیت دارد
\lr{Macro F1-Score}
خواهد بود.

همچنین تمامی نتایج در حالت
\lr{K-fold}
نیز مورد بررسی قرار گرفته است که مطمئن شود واریانس درستی از نتایج داده‌ها وجود داشته باشد.



\شروع{شکل}[ht]
\centerimg{image3}{9cm}
\شرح{نمونه‌ای از نوع نتیجه و دقت‌سنجی اعلامی}
\برچسب{شکل:دقت سنجی}
\پایان{شکل}

\pagebreak

و در آخر توزیع ماتریس درهم‌ریختگی\پانویس{Confusion Matrix} آن نیز بررسی می‌شود که بتوان متوجه شد در چه حوزه‌ یک دستور خوب عمل کرده و در چه حوزه‌ای ضعف داشته است.



\شروع{شکل}[ht]
\centerimg{image4}{9cm}
\شرح{نمونه‌ای از بررسی ماتریس درهم‌ریختگی}
\برچسب{شکل:ماتریس}
\پایان{شکل}
